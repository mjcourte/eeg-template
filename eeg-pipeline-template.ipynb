{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introductory EEG Analysis with SciPy/Python 3\n",
    "\n",
    "I use functions from the Scipy Signal Processing module that sweep a lot of the mathematical details under the rug and let us look at the end-to-end procedure.\n",
    "Most functions that I call are intuitively named and interpretable by a student that has done any kind of signal collection class or lab.\n",
    "I do not use any of the EEG-specific toolboxes that exist for the field standard languages (primarily MATLAB, and to a lesser extent Python).\n",
    "These packages are far more powerful and are set up to manage vendor-specific data formats, but can be hard to approach for a newcomer.\n",
    "\n",
    "This pipeline is based on a 3-channel recording of a basic auditory oddball paradigm designed to elicit a P300 ERP. \n",
    "We know the channel order in the data file:\n",
    "1. TTL\n",
    "2. V EOG (V EEG technically, single electrode)\n",
    "3. H EOG (H EEG technically, single electrode)\n",
    "4. Fz\n",
    "5. Cz\n",
    "6. Pz\n",
    "7. Some other columns that recorded by the script that have no consequence here.\n",
    "\n",
    "This script can be adapted to more channels in the initial assignment of `eeg` array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib notebook\n",
    "import scipy.signal as sig\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User tunable parameters\n",
    "\n",
    "Set the paths to point to your data files.\n",
    "Replace all `None` with values.\n",
    "Adjust the processing parameters and see how they affect the final results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "data_file       = '/path/to/data.ext'\n",
    "sequence_file   = '/path/to/aux/files.ext'\n",
    "\n",
    "# Data info\n",
    "sample_rate     = None # Hertz\n",
    "nyquist         = 0.5 * sample_rate\n",
    "stim_latency    = None # samples - corresponds to our hardware (difference between TTL and soundcard)\n",
    "\n",
    "# Filtering: Butterworth bandpass\n",
    "hpf_freq        = None # Hertz\n",
    "lpf_freq        = None # Hertz\n",
    "filter_order    = None \n",
    "\n",
    "# Filtering: powerline notch\n",
    "plnotch_freq    = None # Hertz\n",
    "plnotch_bw      = None # Hertz\n",
    "\n",
    "# Peak detection\n",
    "d_ttl_threshold = None # microVolts per second\n",
    "blink_threshold = None # microVolts\n",
    "blink_width     = None # samples between blinks\n",
    "\n",
    "# Epoch window definition\n",
    "pre_stim_time   = None # seconds\n",
    "post_stim_time  = None # seconds\n",
    "blink_buf_time  = None # seconds outside of epoch to match blinks\n",
    "blink_buffer    = sample_rate * blink_buf_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial data import and exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Import the data from file\n",
    "data = np.loadtxt(data_file, dtype='double')\n",
    "\n",
    "number_of_samples = data.shape[0]\n",
    "\n",
    "# Plot the raw data - columns of the array vs. row index\n",
    "index = range(number_of_samples)\n",
    "number_of_subplots = data.shape[1]\n",
    "\n",
    "plt.figure(figsize=[10,20])\n",
    "\n",
    "for i in range(number_of_subplots):\n",
    "    ax1 = plt.subplot(number_of_subplots, 1, i+1)\n",
    "    ax1.plot(index,data[:,i])\n",
    "\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above plot can you visually identify any of the traces?\n",
    "\n",
    "We can sort our single data array into seperate arrays for readability.\n",
    "Compare this to your notes from collecting data.\n",
    "You'll need to identify the correct slices of the `data` array that correspond to each type of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttl   = data[:, 0]\n",
    "veog  = data[:, 1]\n",
    "eeg   = data[:, 3:6]\n",
    "number_of_channels = eeg.shape[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you charge ahead with analysis, it is good to look the frequency spectra of the main channel data.\n",
    "This can identify noise or bad data.\n",
    "\n",
    "Use `scipy.signal.periodogram` to make a power spectral density (PSD) plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(freqs, eeg_spectra) = sig.periodogram(eeg, sample_rate, return_onesided=True, axis=0)\n",
    "\n",
    "# Plot spectra\n",
    "fig = plt.figure(figsize=[10,10])\n",
    "\n",
    "for i in range(number_of_channels):\n",
    "    ax1 = plt.subplot(number_of_channels, 1, i+1)\n",
    "    ax1.loglog(freqs, eeg_spectra[:,i])\n",
    "    ax1.set_ylim(1e-2, 1e13)\n",
    "    \n",
    "fig.text(0.50, 0.04, 'Frequency (Hz)', ha='center', fontsize=20)\n",
    "fig.text(0.04, 0.50, r'Power Spectral Density (V$^2$/Hz)', ha='center', va='center', rotation='vertical', fontsize=20)\n",
    "plt.subplots_adjust(hspace=0.25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you have 60 Hz line noise contaminating the data?\n",
    "\n",
    "## Temporal filtering\n",
    "\n",
    "We will filter the data while it is in continuous form to minimize edge ringing.\n",
    "\n",
    "First, design our bandpass and notch filters and apply them only to the EEG data channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design the high-pass and low-pass filter parameters\n",
    "low        = hpf_freq / nyquist\n",
    "high       = lpf_freq / nyquist\n",
    "(b, a)     = sig.butter(filter_order, [low, high], btype='band')\n",
    "\n",
    "# Apply filters using forward/reverse zero-phase method filtfilt\n",
    "eeg_bpfilt = sig.filtfilt(b, a, eeg, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design IIR notch for the powerline filter\n",
    "w0           = plnotch_freq / nyquist\n",
    "Q            = w0 / plnotch_bw\n",
    "(b, a)       = sig.iirnotch(w0, Q)\n",
    "eeg_bpplfilt = sig.filtfilt(b, a, eeg_bpfilt, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bravely ignore the future deprecation warningg and proceed to check your work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(freqs, eeg_filt_spectra) = sig.periodogram(eeg_bpplfilt, sample_rate, return_onesided=True, axis=0)\n",
    "\n",
    "# Plot spectra\n",
    "fig = plt.figure(figsize=[10,10])\n",
    "\n",
    "for i in range(number_of_channels):\n",
    "    ax1 = plt.subplot(number_of_channels, 1, i+1)\n",
    "    ax1.loglog(freqs, eeg_spectra[:,i])\n",
    "    ax1.loglog(freqs, eeg_filt_spectra[:,i])\n",
    "    ax1.set_ylim(1e-2, 1e13)\n",
    "    \n",
    "fig.text(0.50, 0.04, 'Frequency (Hz)', ha='center', fontsize=20)\n",
    "fig.text(0.04, 0.50, r'Power Spectral Density (V$^2$/Hz)', ha='center', va='center', rotation='vertical', fontsize=20)\n",
    "plt.subplots_adjust(hspace=0.25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a periodogram (PSD plot) we can see the filter corners. If you bring your lowpass corner low enough, the powerline notch may not even be necessary. \n",
    "\n",
    "Look at the time domain as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[10,10])\n",
    "\n",
    "for i in range(number_of_channels):\n",
    "    ax1 = plt.subplot(number_of_channels, 1, i+1)\n",
    "    ax1.plot(index, eeg[:,i]-np.mean(eeg[:,i]))\n",
    "    ax1.plot(index, eeg_bpplfilt[:,i])\n",
    "    \n",
    "fig.text(0.50, 0.04, 'Sample', ha='center', fontsize=20)\n",
    "fig.text(0.04, 0.50, r'EEG Signal ($\\mu$V)', ha='center', va='center', rotation='vertical', fontsize=20)\n",
    "plt.subplots_adjust(hspace=0.25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A de-meaned copy of original signals to show them in the same plot.\n",
    "These might affect the y axis limits, so remove these to see the new data clearly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[10,10])\n",
    "\n",
    "for i in range(number_of_channels):\n",
    "    ax1 = plt.subplot(number_of_channels, 1, i+1)\n",
    "    ax1.plot(index, eeg_bpplfilt[:,i])\n",
    "\n",
    "fig.text(0.50, 0.04, 'Sample', ha='center', fontsize=20)\n",
    "fig.text(0.04, 0.50, r'EEG Signal ($\\mu$V)', ha='center', va='center', rotation='vertical', fontsize=20)\n",
    "plt.subplots_adjust(hspace=0.25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are the data aren't intelligible yet? \n",
    "What can you identify in the filtered data?\n",
    "\n",
    "Now the temporal filtering is finished for the continuous data. \n",
    "Next, prepare for epoching our data into trials around stimuli.\n",
    "\n",
    "## Locating trials with the TTL (Stim) channel data\n",
    "\n",
    "The TTL channel is a record of when the computer sent stimulus to the participant.\n",
    "You need to detect the leading edges of the square pulses to identify the samples that mark auditory stimuli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[10,5])\n",
    "plt.plot(index, ttl)\n",
    "plt.ylabel(r'TTL signal ($\\mu$V)', fontsize=20)\n",
    "plt.xlabel('Sample', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the discrete derivative using `numpy.diff` and locate the maxima. \n",
    "The falling edges will be minima.\n",
    "The baseline is not a problem in this approach, so filtering is not necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_ttl = np.diff(ttl, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[10,5])\n",
    "plt.plot(d_ttl)\n",
    "plt.ylabel(r'dTTL ($\\mu$V/s)', fontsize=20)\n",
    "plt.xlabel('Sample', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline should be flat, and the train of impulses can be marked.\n",
    "\n",
    "Next, `scipy.signal.find_peaks` does exactly what it says on the tin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(peaks, properties) = sig.find_peaks(d_ttl, height=d_ttl_threshold)\n",
    "\n",
    "fig = plt.figure(figsize=[10,5])\n",
    "plt.plot(d_ttl)\n",
    "plt.scatter(peaks, properties['peak_heights'], s=50, c='red', marker='o')\n",
    "plt.ylabel(r'dTTL ($\\mu$V/s)', fontsize=20)\n",
    "plt.xlabel('Sample', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zoom and enhance.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[10,5])\n",
    "plt.plot(d_ttl)\n",
    "plt.scatter(peaks, properties['peak_heights'], s=50, c='red', marker='o')\n",
    "plt.ylabel(r'dTTL ($\\mu$V/s)', fontsize=20)\n",
    "plt.xlabel('Sample', fontsize=20)\n",
    "plt.xlim(left=1000, right=10000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values you care about are the sample numbers, which are contained in `peaks`.\n",
    "\n",
    "### Compensate for hardware latency\n",
    "\n",
    "If you are properly careful you would have measured the latency in your EEG system between the TTL pulse edge and the stimulus delivery.\n",
    "You can offset the values of the `peaks` array to compensate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks = peaks - stim_latency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check that these values line up with the leading edges of the pulse.\n",
    "Bring the pre-stim baseline to around zero to illustrate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[10,5])\n",
    "plt.plot(index, ttl - np.mean(ttl[:3000]))\n",
    "plt.scatter(peaks, np.zeros(peaks.shape), s=50, c='red', marker='o')\n",
    "plt.ylabel(r'(shifted) TTL signal ($\\mu$V)', fontsize=20)\n",
    "plt.xlabel('Sample', fontsize=20)\n",
    "plt.xlim(left=1000, right=10000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define trials using triggers and processing parameters\n",
    "\n",
    "Now that the stimuli samples are known, we need to identify the surrounding temporal regions of interest within the continuous data streams.\n",
    "Derive epochs by anchoring around the trigger markers, and extending some specificed time before and after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = np.array([peaks - pre_stim_time * sample_rate, peaks + post_stim_time * sample_rate ])\n",
    "epochs = epochs.T\n",
    "\n",
    "number_of_trials = epochs.shape[0]\n",
    "\n",
    "print(epochs.shape)\n",
    "#print(epochs[:11,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "200 trials, just as planned.\n",
    "The array contains the start and end sample labels of each epoch.\n",
    "\n",
    "The trials need to be sorted according to their condition.\n",
    "\n",
    "## Identifying standard and deviant trials using a sequence\n",
    "\n",
    "We have a sequence file that labels the deviant tones that should contain the P300.\n",
    "This information will be used when averaging trials by condition.\n",
    "Note that I subtract 1 from the list, element-wise, because the list counts from 1, whereas Python is counts from 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deviant_seq = np.loadtxt(sequence_file, delimiter=',', dtype='int')\n",
    "deviant_seq -= 1\n",
    "print(deviant_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, we can store this list inside the epoch_samples array.\n",
    "Create an extra column to mark blinks/artifacts trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = np.zeros([epochs.shape[0], epochs.shape[1] + 2], dtype='int')\n",
    "tmp[:,:2] = epochs\n",
    "tmp[deviant_seq, 2] = 1\n",
    "epochs = tmp\n",
    "\n",
    "print(epochs[:11, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding bad trials from blinks in V EOG\n",
    "\n",
    "Apply a high-pass filter to V EOG in order to straighten out the baseline.\n",
    "Use peak detection in V EOG to find artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[10,5])\n",
    "plt.plot(index, veog)\n",
    "plt.ylabel(r'Raw V EOG signal ($\\mu$V)', fontsize=20)\n",
    "plt.xlabel('Sample', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to detect peaks from a signal with drifting baseline, but we can also deal with it via a HPF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design the high-pass filter parameters\n",
    "low       = hpf_freq / nyquist\n",
    "(b, a)    = sig.butter(filter_order, low, btype='highpass')\n",
    "veog_filt = sig.filtfilt(b, a, veog, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[10,5])\n",
    "plt.plot(index, veog - np.mean(veog))\n",
    "plt.plot(index, veog_filt)\n",
    "plt.ylabel(r'Filtered V EOG ($\\mu$V)', fontsize=20)\n",
    "plt.xlabel('Sample', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De-meaned the original signal for clarity.\n",
    "Compare the baselines, and make sure the blink peaks are intact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(blinks, properties) = sig.find_peaks(veog_filt, height=blink_threshold, distance=blink_width)\n",
    "\n",
    "fig = plt.figure(figsize=[10,5])\n",
    "plt.plot(index, veog_filt)\n",
    "plt.scatter(blinks, properties['peak_heights'], s=50, c='red', marker='o')\n",
    "plt.ylabel(r'V EOG ($\\mu$V)', fontsize=20)\n",
    "plt.xlabel('Sample', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many blinks which is not ideal.\n",
    "Note that I had to tune the `find_peaks` parameters from its last use in triggers.\n",
    "We must return to our `epochs` and give them the bad news."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "reject_standard = 0\n",
    "reject_deviant = 0\n",
    "\n",
    "for i in range(number_of_trials):\n",
    "    \n",
    "    if any(np.logical_and(blinks>=(epochs[i,0]-blink_buffer),   # For each trial, is there a blink in its\n",
    "                          blinks<=(epochs[i,1]+blink_buffer))): # sample span +/- buffer region\n",
    "        epochs[i, -1] = 1            # Mark this trial with a 1 to indicate blink is present\n",
    "    \n",
    "        if epochs[i, -2] == 1:       # Count how many trials we are losing of each kind\n",
    "            reject_deviant  += 1\n",
    "\n",
    "        elif epochs[i, -2] == 0:\n",
    "            reject_standard += 1\n",
    "            \n",
    "    else: # If you get your logic wrong, this lets it clean itself on re-run\n",
    "        epochs[i, -1] = 0\n",
    "\n",
    "print('Number of blinks/artifacts: %u' % blinks.shape)\n",
    "print('Standard trials lost to blinks: %u' % reject_standard)\n",
    "print('Deviant trials lost to blinks: %u' % reject_deviant)\n",
    "print('\\nBlinks:')\n",
    "print(blinks)\n",
    "print('\\n\\tStart\\tStop\\tTrial\\tBad')\n",
    "print(epochs[:21, :])\n",
    "print('[...]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many trials did you lose to artifacts?\n",
    "How many do you have left of each conditions?\n",
    "\n",
    "## Segment data into epochs and average like-trials\n",
    "\n",
    "Using our epochs array that contains the time, type, and rejection of every trial, we can reshape the `eeg_bpplfilt` array into trials.\n",
    "\n",
    "Currently, the shape of the eeg data is samples-by-channels.\n",
    "First, seperate this into (samples per trial)-by-channels-by-(number of trials), then seperate into standard and deviant.\n",
    "During the process, subtract the mean of the pre-stimulus portion of the epoch window out of each epoch.\n",
    "This brings every trial to a similar baseline to prevent issues with averaging.\n",
    "With blinks recorded in the same array, check each trial as we go in case it needs to be ignored by the average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_window    = int(sample_rate * (pre_stim_time + post_stim_time)) + 1 # Include the peak sample\n",
    "baseline_window = int(sample_rate * pre_stim_time)                        # both in units of samples\n",
    "\n",
    "standard_trial  = np.zeros([epoch_window, number_of_channels], dtype='double')\n",
    "deviant_trial   = np.zeros([epoch_window, number_of_channels], dtype='double')\n",
    "tmp             = np.zeros([epoch_window, number_of_channels], dtype='double')\n",
    "\n",
    "keep_standard   = 0\n",
    "keep_deviant    = 0\n",
    "\n",
    "for i in range(number_of_trials):\n",
    "    \n",
    "    if epochs[i, -1] == 1: # Check if bad trial up front in the loop, as it skips the rest if true\n",
    "        continue\n",
    "        \n",
    "    tmp = eeg_bpplfilt[epochs[i,0]:epochs[i,1], :]  # Select data\n",
    "    tmp -= np.mean(tmp[:baseline_window,:], axis=0) # Subtract mean of baseline\n",
    "    \n",
    "    if epochs[i, -2] == 0: # If standard, do this\n",
    "        standard_trial += tmp\n",
    "        keep_standard  += 1\n",
    "    \n",
    "    if epochs[i, -2] == 1: # If deviant, do this\n",
    "        deviant_trial  += tmp\n",
    "        keep_deviant   += 1\n",
    "        \n",
    "standard_trial /= keep_standard # Divide to complete averages\n",
    "deviant_trial  /= keep_deviant\n",
    "\n",
    "print('Standard trials kept: %u' % keep_standard)\n",
    "print('Deviant trials kept: %u' % keep_deviant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That previous step was terse.\n",
    "The whole anaylsis came together in just a few lines of code.\n",
    "The `for` loop iterated through all trials to do the following:\n",
    "1. Check if this trial was flagged for containing an artifact or blink (if true skip to next trial),\n",
    "1. Subtract the average of the baseline pre-stimulus signal from each trial (each channel seperately),\n",
    "1. Sort trial into standard or deviant pools, \n",
    "1. Sum trial into the correct pool,\n",
    "1. Keep track of how many trials were summed into each pool.\n",
    "\n",
    "After the loop, each trial summation is divided by the number of trials that were summed into it, this is the average.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_axis = ( np.arange(epoch_window) / sample_rate - pre_stim_time ) * 1000 # Convert seconds to ms\n",
    "\n",
    "fig = plt.figure(figsize=[10,10])\n",
    "\n",
    "for i in range(number_of_channels):\n",
    "    ax1 = plt.subplot(number_of_channels, 1, i+1)\n",
    "    ax1.plot(time_axis, standard_trial[:,i]/1000, label='Standard')  # Convert uV to mV for readability\n",
    "    ax1.plot(time_axis, deviant_trial[:,i]/1000, label='Deviant')\n",
    "    ax1.set_ylim(-10, 10)\n",
    "    ax1.grid()\n",
    "    ax1.legend()\n",
    "    \n",
    "fig.text(0.50, 0.04, 'Time, stimulus relative (ms)', ha='center', fontsize=20)\n",
    "fig.text(0.04, 0.50, r'Trial averaged EEG signal (mV)', ha='center', va='center', rotation='vertical', fontsize=20)\n",
    "fig.text(0.14, 0.85, 'Electrode: Fz', ha='left', fontsize=20)\n",
    "fig.text(0.14, 0.58, 'Electrode: Cz', ha='left', fontsize=20)\n",
    "fig.text(0.14, 0.31, 'Electrode: Pz', ha='left', fontsize=20)\n",
    "plt.subplots_adjust(hspace = 0.25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both standard and deviants should have a positive peak at around 100 ms, the N100.\n",
    "This indicates the participant was hearing something.\n",
    "Do you see an expanded negative deflecton in the 250-300 ms window of the deviant traces as compared to the standards?\n",
    "This is the P300.\n",
    "\n",
    "Note that the polarity of the peak label (P/N) corresponds physiological excitation or inhibition, not voltage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
